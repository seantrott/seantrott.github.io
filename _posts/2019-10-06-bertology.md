---
layout: post
title: Word embeddings, pt. 1
---

The primary goal of this post is to summarize several recent papers exploring what [BERT](https://github.com/google-research/bert), a contextualized word embedding model, can and can't do. If you're new to word embeddings in general, my [other post](https://seantrott.github.io/embeddings/) has more background.

# Introduction: contextualized word embeddings

( fill in )

# BERT investigations

## Assessing BERT's syntactic knowledge

include:
- Goldberg (2019)
- Coenen et al (2019)
- Hewitt & Manning (2019)

## Edge probing: what does BERT know, and where?

include: 
- Tenney et al (2019)

## Commonsense in BERT 

Include:
- Forbes et al (2019)  
- Niven & Kao (2019)


Outline:

Coenen, A., Reif, E., Yuan, A., Kim, B., Pearce, A., Vi√©gas, F., & Wattenberg, M. (2019). Visualizing and Measuring the Geometry of BERT. arXiv preprint arXiv:1906.02715. 

Forbes, M., Holtzman, A., & Choi, Y. (2019). Do Neural Language Representations Learn Physical Commonsense?. arXiv preprint arXiv:1908.02899.

Goldberg, Y. (2019). Assessing BERT's Syntactic Abilities. arXiv preprint arXiv:1901.05287. 

Hewitt, J., & Manning, C. D. (2019, June). A structural probe for finding syntax in word representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4129-4138).

Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., & Sayres, R. (2017). Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). arXiv preprint arXiv:1711.11279.

Niven, T., & Kao, H. Y. (2019). Probing neural network comprehension of natural language arguments. arXiv preprint arXiv:1907.07355.

Tenney, I., Das, D., & Pavlick, E. (2019). Bert rediscovers the classical nlp pipeline. arXiv preprint arXiv:1905.05950. 

